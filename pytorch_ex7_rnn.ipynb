{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "attached-offering",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "balanced-horizon",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, Math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "polished-scene",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "# import torch.nn.init as init\n",
    "# from torchvision import datasets\n",
    "# from torchvision import transforms\n",
    "# from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "invisible-morrison",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden = 35\n",
    "lr = 0.01\n",
    "epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "physical-intention",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_string = 'hello pytorch. how long can a rnn cell remember? i am a boy and you are a girl. can you make a pancake for mommy?'\n",
    "chars = 'abcdefghijklmnopqrstuvwxyz ?!.,:;01'\n",
    "char_list = [i for i in chars]\n",
    "n_letters = len(char_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "protecting-command",
   "metadata": {},
   "outputs": [],
   "source": [
    "def str2onehot(string):\n",
    "    start = np.zeros(shape = n_letters, dtype = int)\n",
    "    end = np.zeros(shape = n_letters, dtype = int)\n",
    "    start[-2] = 1\n",
    "    end[-1] = 1\n",
    "    for c in string:\n",
    "        idx = char_list.index(c)\n",
    "        zero = np.zeros(shape = n_letters, dtype = int)\n",
    "        zero[idx] = 1\n",
    "        start = np.vstack([start, zero])\n",
    "    output = np.vstack([start, end])\n",
    "    return output\n",
    "\n",
    "def onehot2word(onehot_1):\n",
    "    onehot = torch.Tensor.numpy(onehot_1)\n",
    "    return char_list[onehot.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "essential-volleyball",
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(my_RNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.in2hid = nn.Linear(input_size, hidden_size)\n",
    "        self.hid2hid = nn.Linear(hidden_size, hidden_size)\n",
    "        self.hid2out = nn.Linear(hidden_size, output_size)\n",
    "        self.act_fn = nn.Tanh()\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        hidden = self.act_fn(self.in2hid(input)+self.hid2hid(hidden))\n",
    "        \n",
    "#         hidden = self.act_fn(self.hid2hid(hidden)+self.hid2hid(hidden))\n",
    "        output = self.hid2out(hidden)\n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "internal-smoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = my_RNN(n_letters, n_hidden, n_letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "pregnant-conspiracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "moderate-curve",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = torch.from_numpy(str2onehot(my_string)).type_as(torch.FloatTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "resident-huntington",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(4.9923, grad_fn=<AddBackward0>)\n",
      "tensor(2.4587, grad_fn=<AddBackward0>)\n",
      "tensor(1.9323, grad_fn=<AddBackward0>)\n",
      "tensor(1.5586, grad_fn=<AddBackward0>)\n",
      "tensor(1.2615, grad_fn=<AddBackward0>)\n",
      "tensor(1.1694, grad_fn=<AddBackward0>)\n",
      "tensor(1.0262, grad_fn=<AddBackward0>)\n",
      "tensor(0.9069, grad_fn=<AddBackward0>)\n",
      "tensor(0.8480, grad_fn=<AddBackward0>)\n",
      "tensor(0.7911, grad_fn=<AddBackward0>)\n",
      "tensor(0.7159, grad_fn=<AddBackward0>)\n",
      "tensor(0.6842, grad_fn=<AddBackward0>)\n",
      "tensor(0.6320, grad_fn=<AddBackward0>)\n",
      "tensor(0.7325, grad_fn=<AddBackward0>)\n",
      "tensor(0.7132, grad_fn=<AddBackward0>)\n",
      "tensor(0.6225, grad_fn=<AddBackward0>)\n",
      "tensor(0.5788, grad_fn=<AddBackward0>)\n",
      "tensor(0.6615, grad_fn=<AddBackward0>)\n",
      "tensor(0.5704, grad_fn=<AddBackward0>)\n",
      "tensor(0.5413, grad_fn=<AddBackward0>)\n",
      "tensor(0.5319, grad_fn=<AddBackward0>)\n",
      "tensor(0.4991, grad_fn=<AddBackward0>)\n",
      "tensor(0.5625, grad_fn=<AddBackward0>)\n",
      "tensor(0.5188, grad_fn=<AddBackward0>)\n",
      "tensor(0.4806, grad_fn=<AddBackward0>)\n",
      "tensor(0.4630, grad_fn=<AddBackward0>)\n",
      "tensor(0.4491, grad_fn=<AddBackward0>)\n",
      "tensor(0.4881, grad_fn=<AddBackward0>)\n",
      "tensor(0.4565, grad_fn=<AddBackward0>)\n",
      "tensor(0.4408, grad_fn=<AddBackward0>)\n",
      "tensor(0.4520, grad_fn=<AddBackward0>)\n",
      "tensor(0.4358, grad_fn=<AddBackward0>)\n",
      "tensor(0.4249, grad_fn=<AddBackward0>)\n",
      "tensor(0.4152, grad_fn=<AddBackward0>)\n",
      "tensor(0.4414, grad_fn=<AddBackward0>)\n",
      "tensor(0.4231, grad_fn=<AddBackward0>)\n",
      "tensor(0.4069, grad_fn=<AddBackward0>)\n",
      "tensor(0.3956, grad_fn=<AddBackward0>)\n",
      "tensor(0.3910, grad_fn=<AddBackward0>)\n",
      "tensor(0.4703, grad_fn=<AddBackward0>)\n",
      "tensor(0.4180, grad_fn=<AddBackward0>)\n",
      "tensor(0.4022, grad_fn=<AddBackward0>)\n",
      "tensor(0.3898, grad_fn=<AddBackward0>)\n",
      "tensor(0.3812, grad_fn=<AddBackward0>)\n",
      "tensor(0.4345, grad_fn=<AddBackward0>)\n",
      "tensor(0.3895, grad_fn=<AddBackward0>)\n",
      "tensor(0.3751, grad_fn=<AddBackward0>)\n",
      "tensor(0.3673, grad_fn=<AddBackward0>)\n",
      "tensor(0.4181, grad_fn=<AddBackward0>)\n",
      "tensor(0.3788, grad_fn=<AddBackward0>)\n",
      "tensor(0.3632, grad_fn=<AddBackward0>)\n",
      "tensor(0.3566, grad_fn=<AddBackward0>)\n",
      "tensor(0.3962, grad_fn=<AddBackward0>)\n",
      "tensor(0.3618, grad_fn=<AddBackward0>)\n",
      "tensor(0.3492, grad_fn=<AddBackward0>)\n",
      "tensor(0.4244, grad_fn=<AddBackward0>)\n",
      "tensor(0.3573, grad_fn=<AddBackward0>)\n",
      "tensor(0.3396, grad_fn=<AddBackward0>)\n",
      "tensor(0.3716, grad_fn=<AddBackward0>)\n",
      "tensor(0.3856, grad_fn=<AddBackward0>)\n",
      "tensor(0.3490, grad_fn=<AddBackward0>)\n",
      "tensor(0.3841, grad_fn=<AddBackward0>)\n",
      "tensor(0.3351, grad_fn=<AddBackward0>)\n",
      "tensor(0.3291, grad_fn=<AddBackward0>)\n",
      "tensor(0.3667, grad_fn=<AddBackward0>)\n",
      "tensor(0.3353, grad_fn=<AddBackward0>)\n",
      "tensor(0.3199, grad_fn=<AddBackward0>)\n",
      "tensor(0.3183, grad_fn=<AddBackward0>)\n",
      "tensor(0.3087, grad_fn=<AddBackward0>)\n",
      "tensor(0.5119, grad_fn=<AddBackward0>)\n",
      "tensor(0.3961, grad_fn=<AddBackward0>)\n",
      "tensor(0.3182, grad_fn=<AddBackward0>)\n",
      "tensor(0.3402, grad_fn=<AddBackward0>)\n",
      "tensor(0.3074, grad_fn=<AddBackward0>)\n",
      "tensor(0.2975, grad_fn=<AddBackward0>)\n",
      "tensor(0.4383, grad_fn=<AddBackward0>)\n",
      "tensor(0.3241, grad_fn=<AddBackward0>)\n",
      "tensor(0.3012, grad_fn=<AddBackward0>)\n",
      "tensor(0.2915, grad_fn=<AddBackward0>)\n",
      "tensor(0.2853, grad_fn=<AddBackward0>)\n",
      "tensor(0.3588, grad_fn=<AddBackward0>)\n",
      "tensor(0.3387, grad_fn=<AddBackward0>)\n",
      "tensor(0.3025, grad_fn=<AddBackward0>)\n",
      "tensor(0.2904, grad_fn=<AddBackward0>)\n",
      "tensor(0.2828, grad_fn=<AddBackward0>)\n",
      "tensor(0.3118, grad_fn=<AddBackward0>)\n",
      "tensor(0.2929, grad_fn=<AddBackward0>)\n",
      "tensor(0.2973, grad_fn=<AddBackward0>)\n",
      "tensor(0.2821, grad_fn=<AddBackward0>)\n",
      "tensor(0.2728, grad_fn=<AddBackward0>)\n",
      "tensor(0.2809, grad_fn=<AddBackward0>)\n",
      "tensor(0.2838, grad_fn=<AddBackward0>)\n",
      "tensor(0.2702, grad_fn=<AddBackward0>)\n",
      "tensor(0.2975, grad_fn=<AddBackward0>)\n",
      "tensor(0.2925, grad_fn=<AddBackward0>)\n",
      "tensor(0.2677, grad_fn=<AddBackward0>)\n",
      "tensor(0.2611, grad_fn=<AddBackward0>)\n",
      "tensor(0.5665, grad_fn=<AddBackward0>)\n",
      "tensor(0.2937, grad_fn=<AddBackward0>)\n",
      "tensor(0.2690, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for ii in range(epochs):\n",
    "    rnn.zero_grad()\n",
    "    total_loss = 0\n",
    "    hidden = rnn.init_hidden()\n",
    "    \n",
    "    ## go all sequence and sum all loss\n",
    "    for jj in range(one_hot.size()[0]-1):\n",
    "        input_ = one_hot[jj:jj+1, :]\n",
    "        target = one_hot[jj+1]\n",
    "        \n",
    "        output, hidden = rnn.forward(input_, hidden)\n",
    "        loss = loss_func(output.view(-1), target.view(-1))\n",
    "        \n",
    "        total_loss += loss\n",
    "        input_ = output\n",
    "    \n",
    "    # update weight after calculating all loss through sequence\n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if ii%10 == 0:\n",
    "        print(total_loss)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ready-prefix",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(0.2601, grad_fn=<AddBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "peripheral-humanity",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ 0.2751,  0.2459, -0.3100,  0.5328, -0.1593, -0.0794,  0.4544, -0.0714,\n",
       "         -0.4266,  0.4525,  0.5068,  0.5291,  0.3843, -0.4324,  0.1027, -0.2997,\n",
       "         -0.2884, -0.4481,  0.7165,  0.7853, -0.7908,  0.3858,  0.5347,  0.0632,\n",
       "          0.3540,  0.4212, -0.0365, -0.0933, -0.2715,  0.3714,  0.0446, -0.3503,\n",
       "         -0.2726,  0.2046, -0.1102]], grad_fn=<TanhBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "hidden # weight of 2nd hidden layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "inappropriate-seattle",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 35])"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "indie-savage",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "hello  mncra    a n a r r r a a a a   a a a a a   a a a   a   a a a   a a   a                                    \n"
     ]
    }
   ],
   "source": [
    "start = torch.zeros(1, n_letters)\n",
    "start[:,-2] = 1\n",
    "\n",
    "with torch.no_grad():\n",
    "    hidden = rnn.init_hidden()\n",
    "    input_ = start\n",
    "    output_string = ''\n",
    "    for ii in range(len(my_string)):\n",
    "        output, hidden = rnn.forward(input_, hidden)\n",
    "        output_string += onehot2word(output.data)\n",
    "        input_ = output\n",
    "        \n",
    "print(output_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "brilliant-mauritius",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[ 1.2289e-01, -3.4028e-02,  7.6688e-02,  6.6910e-03,  8.5520e-04,\n",
       "           2.5233e-03,  1.1776e-02,  6.8985e-03,  5.6530e-02,  2.4144e-10,\n",
       "           2.9340e-02,  4.8596e-02,  5.1241e-02,  1.0144e-01,  1.1097e-01,\n",
       "          -2.1675e-02, -5.2606e-25,  2.3063e-03,  1.4199e-23,  1.8046e-03,\n",
       "           4.8106e-02, -2.9513e-21,  6.8246e-03, -1.5174e-22,  3.3946e-02,\n",
       "           4.5964e-23,  3.3706e-01,  1.2872e-02, -4.4398e-12,  8.8163e-03,\n",
       "          -1.6006e-19,  1.3808e-17,  1.2806e-22, -7.9921e-22, -1.9913e-02]],\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-6.2239e-02, -9.4547e-05,  1.1981e-01,  1.1001e-01, -7.0248e-02,\n",
       "          -5.8333e-02, -1.3141e-01, -5.8123e-02,  6.2774e-02, -1.7042e-02,\n",
       "           1.4157e-01, -2.0681e-01, -1.8637e-01, -1.8295e-02, -1.6850e-01,\n",
       "          -2.8630e-02,  4.2617e-02,  1.9618e-02,  1.3478e-01, -1.9802e-01,\n",
       "           1.0037e-02,  1.1015e-01, -1.1598e-01, -1.7958e-02, -4.8180e-02,\n",
       "          -1.2899e-01,  1.8526e-01,  4.8830e-02,  3.2505e-02, -1.0717e-02,\n",
       "          -5.2186e-02, -9.0860e-03,  5.4602e-02, -1.3878e-01, -2.0782e-01]],\n",
       "        grad_fn=<TanhBackward>))"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "rnn.forward(input_, hidden)"
   ]
  },
  {
   "source": [
    "a를 출력하도록 saturated 된 것으로 보인다.\n",
    "\n",
    "아주 간단히 구현한 것이고, 학습한 문자열도 길지 않아 엄청 좋은 결과를 얻기는 힘들다.\n",
    "\n",
    "그저 torch로 rnn을 어떻게 구현하는지에 대해서 초점을 맞추자"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "hidden layer를 하나 늘려보기"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_RNN_2(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(my_RNN_2, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.in2hid = nn.Linear(input_size, hidden_size)\n",
    "        self.hid2hid = nn.Linear(hidden_size, hidden_size)\n",
    "        self.hid2out = nn.Linear(hidden_size, output_size)\n",
    "        self.act_fn = nn.Tanh()\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        hidden = self.act_fn(self.in2hid(input)+self.hid2hid(hidden))\n",
    "        \n",
    "        hidden = self.act_fn(self.hid2hid(hidden)+self.hid2hid(hidden))\n",
    "        output = self.hid2out(hidden)\n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_2 = my_RNN_2(n_letters, n_hidden, n_letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(rnn_2.parameters(), lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(6.7310, grad_fn=<AddBackward0>)\n",
      "tensor(2.7471, grad_fn=<AddBackward0>)\n",
      "tensor(2.2158, grad_fn=<AddBackward0>)\n",
      "tensor(1.8703, grad_fn=<AddBackward0>)\n",
      "tensor(1.6346, grad_fn=<AddBackward0>)\n",
      "tensor(1.5235, grad_fn=<AddBackward0>)\n",
      "tensor(1.4223, grad_fn=<AddBackward0>)\n",
      "tensor(1.3180, grad_fn=<AddBackward0>)\n",
      "tensor(1.1885, grad_fn=<AddBackward0>)\n",
      "tensor(1.2760, grad_fn=<AddBackward0>)\n",
      "tensor(1.0656, grad_fn=<AddBackward0>)\n",
      "tensor(1.2328, grad_fn=<AddBackward0>)\n",
      "tensor(1.0766, grad_fn=<AddBackward0>)\n",
      "tensor(0.9415, grad_fn=<AddBackward0>)\n",
      "tensor(0.9911, grad_fn=<AddBackward0>)\n",
      "tensor(0.8892, grad_fn=<AddBackward0>)\n",
      "tensor(0.8268, grad_fn=<AddBackward0>)\n",
      "tensor(0.9249, grad_fn=<AddBackward0>)\n",
      "tensor(0.8209, grad_fn=<AddBackward0>)\n",
      "tensor(0.7585, grad_fn=<AddBackward0>)\n",
      "tensor(0.8697, grad_fn=<AddBackward0>)\n",
      "tensor(0.7923, grad_fn=<AddBackward0>)\n",
      "tensor(0.7380, grad_fn=<AddBackward0>)\n",
      "tensor(0.6808, grad_fn=<AddBackward0>)\n",
      "tensor(0.7172, grad_fn=<AddBackward0>)\n",
      "tensor(0.6528, grad_fn=<AddBackward0>)\n",
      "tensor(0.6352, grad_fn=<AddBackward0>)\n",
      "tensor(0.6674, grad_fn=<AddBackward0>)\n",
      "tensor(0.6122, grad_fn=<AddBackward0>)\n",
      "tensor(0.6496, grad_fn=<AddBackward0>)\n",
      "tensor(0.5846, grad_fn=<AddBackward0>)\n",
      "tensor(0.6643, grad_fn=<AddBackward0>)\n",
      "tensor(0.5777, grad_fn=<AddBackward0>)\n",
      "tensor(0.5408, grad_fn=<AddBackward0>)\n",
      "tensor(0.6245, grad_fn=<AddBackward0>)\n",
      "tensor(0.5539, grad_fn=<AddBackward0>)\n",
      "tensor(0.5229, grad_fn=<AddBackward0>)\n",
      "tensor(0.6091, grad_fn=<AddBackward0>)\n",
      "tensor(0.6014, grad_fn=<AddBackward0>)\n",
      "tensor(0.5386, grad_fn=<AddBackward0>)\n",
      "tensor(0.4974, grad_fn=<AddBackward0>)\n",
      "tensor(0.4734, grad_fn=<AddBackward0>)\n",
      "tensor(0.5746, grad_fn=<AddBackward0>)\n",
      "tensor(0.4825, grad_fn=<AddBackward0>)\n",
      "tensor(0.4546, grad_fn=<AddBackward0>)\n",
      "tensor(0.5599, grad_fn=<AddBackward0>)\n",
      "tensor(0.4703, grad_fn=<AddBackward0>)\n",
      "tensor(0.4411, grad_fn=<AddBackward0>)\n",
      "tensor(0.4184, grad_fn=<AddBackward0>)\n",
      "tensor(0.5328, grad_fn=<AddBackward0>)\n",
      "tensor(0.4466, grad_fn=<AddBackward0>)\n",
      "tensor(0.4106, grad_fn=<AddBackward0>)\n",
      "tensor(0.3902, grad_fn=<AddBackward0>)\n",
      "tensor(0.5252, grad_fn=<AddBackward0>)\n",
      "tensor(0.4232, grad_fn=<AddBackward0>)\n",
      "tensor(0.3882, grad_fn=<AddBackward0>)\n",
      "tensor(0.3674, grad_fn=<AddBackward0>)\n",
      "tensor(0.4142, grad_fn=<AddBackward0>)\n",
      "tensor(0.3708, grad_fn=<AddBackward0>)\n",
      "tensor(0.3484, grad_fn=<AddBackward0>)\n",
      "tensor(0.3751, grad_fn=<AddBackward0>)\n",
      "tensor(0.4329, grad_fn=<AddBackward0>)\n",
      "tensor(0.3679, grad_fn=<AddBackward0>)\n",
      "tensor(0.3341, grad_fn=<AddBackward0>)\n",
      "tensor(0.3198, grad_fn=<AddBackward0>)\n",
      "tensor(0.3341, grad_fn=<AddBackward0>)\n",
      "tensor(0.4488, grad_fn=<AddBackward0>)\n",
      "tensor(0.3674, grad_fn=<AddBackward0>)\n",
      "tensor(0.3294, grad_fn=<AddBackward0>)\n",
      "tensor(0.3102, grad_fn=<AddBackward0>)\n",
      "tensor(0.2967, grad_fn=<AddBackward0>)\n",
      "tensor(0.4769, grad_fn=<AddBackward0>)\n",
      "tensor(0.3646, grad_fn=<AddBackward0>)\n",
      "tensor(0.3143, grad_fn=<AddBackward0>)\n",
      "tensor(0.2952, grad_fn=<AddBackward0>)\n",
      "tensor(0.2915, grad_fn=<AddBackward0>)\n",
      "tensor(0.3412, grad_fn=<AddBackward0>)\n",
      "tensor(0.3035, grad_fn=<AddBackward0>)\n",
      "tensor(0.2806, grad_fn=<AddBackward0>)\n",
      "tensor(0.3487, grad_fn=<AddBackward0>)\n",
      "tensor(0.3337, grad_fn=<AddBackward0>)\n",
      "tensor(0.2992, grad_fn=<AddBackward0>)\n",
      "tensor(0.2719, grad_fn=<AddBackward0>)\n",
      "tensor(0.2779, grad_fn=<AddBackward0>)\n",
      "tensor(0.3302, grad_fn=<AddBackward0>)\n",
      "tensor(0.2719, grad_fn=<AddBackward0>)\n",
      "tensor(0.2579, grad_fn=<AddBackward0>)\n",
      "tensor(0.2766, grad_fn=<AddBackward0>)\n",
      "tensor(0.3417, grad_fn=<AddBackward0>)\n",
      "tensor(0.2729, grad_fn=<AddBackward0>)\n",
      "tensor(0.2509, grad_fn=<AddBackward0>)\n",
      "tensor(0.2429, grad_fn=<AddBackward0>)\n",
      "tensor(0.3440, grad_fn=<AddBackward0>)\n",
      "tensor(0.2660, grad_fn=<AddBackward0>)\n",
      "tensor(0.2431, grad_fn=<AddBackward0>)\n",
      "tensor(0.2812, grad_fn=<AddBackward0>)\n",
      "tensor(0.2542, grad_fn=<AddBackward0>)\n",
      "tensor(0.2333, grad_fn=<AddBackward0>)\n",
      "tensor(0.2894, grad_fn=<AddBackward0>)\n",
      "tensor(0.2558, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for ii in range(epochs):\n",
    "    rnn_2.zero_grad()\n",
    "    total_loss = 0\n",
    "    hidden = rnn_2.init_hidden()\n",
    "    \n",
    "    ## go all sequence and sum all loss\n",
    "    for jj in range(one_hot.size()[0]-1):\n",
    "        input_ = one_hot[jj:jj+1, :]\n",
    "        target = one_hot[jj+1]\n",
    "        \n",
    "        output, hidden = rnn_2.forward(input_, hidden)\n",
    "        loss = loss_func(output.view(-1), target.view(-1))\n",
    "        \n",
    "        total_loss += loss\n",
    "        input_ = output\n",
    "    \n",
    "    # update weight after calculating all loss through sequence\n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if ii%10 == 0:\n",
    "        print(total_loss)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "helle  en arenramenana oelcay arena eny  oym arank ayoyrarnea o   ay ako oyonrk a ee a rnoyo loarle cel o raeo ay\n"
     ]
    }
   ],
   "source": [
    "start = torch.zeros(1, n_letters)\n",
    "start[:,-2] = 1\n",
    "\n",
    "with torch.no_grad():\n",
    "    hidden = rnn_2.init_hidden()\n",
    "    input_ = start\n",
    "    output_string = ''\n",
    "    for ii in range(len(my_string)):\n",
    "        output, hidden = rnn_2.forward(input_, hidden)\n",
    "        output_string += onehot2word(output.data)\n",
    "        input_ = output\n",
    "        \n",
    "print(output_string)"
   ]
  },
  {
   "source": [
    "이전보다 saturation되는 경향은 덜하나, 여전히 어떤 말인지 알아보기는 힘들다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.12 64-bit ('bt': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "interpreter": {
   "hash": "a40cf4423ec2b7d3ac5038b9c4bc2a5fd550178d10053adc442af0d8750dc3c0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}